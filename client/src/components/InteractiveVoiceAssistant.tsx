import React, { useState, useEffect, useRef } from 'react';
import { useUser } from '@clerk/clerk-react';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { useToast } from '@/hooks/use-toast';
import { 
  Mic, 
  MicOff, 
  Volume2, 
  VolumeX,
  Loader2
} from 'lucide-react';
import { cn } from '@/lib/utils';

interface InteractiveVoiceAssistantProps {
  className?: string;
}

export function InteractiveVoiceAssistant({ className }: InteractiveVoiceAssistantProps) {
  const { user } = useUser();
  const { toast } = useToast();
  
  // State management
  const [isRecording, setIsRecording] = useState(false);
  const [isAssistantSpeaking, setIsAssistantSpeaking] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [buttonText, setButtonText] = useState("Konumak i癟in Bas覺l覺 Tutun");
  
  // Refs for media handling
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const assistantAudioRef = useRef<HTMLAudioElement | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  // Clean up on unmount
  useEffect(() => {
    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (assistantAudioRef.current) {
        assistantAudioRef.current.pause();
      }
    };
  }, []);

  // Start recording when button is pressed
  const startRecording = async () => {
    try {
      if (isAssistantSpeaking) {
        // Stop assistant if speaking
        stopAssistant();
        return;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        await processRecording();
      };

      mediaRecorder.start();
      setIsRecording(true);
      setButtonText("Dinliyorum... B覺rak覺n");
      
    } catch (error) {
      console.error('Error starting recording:', error);
      toast({
        title: "Hata!",
        description: "Mikrofon eriimi al覺namad覺.",
        variant: "destructive",
      });
    }
  };

  // Stop recording when button is released
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsProcessing(true);
      setButtonText("襤leniyor...");
      
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    }
  };

  // Process the recorded audio
  const processRecording = async () => {
    try {
      if (audioChunksRef.current.length === 0) {
        setIsProcessing(false);
        setButtonText("Konumak i癟in Bas覺l覺 Tutun");
        return;
      }

      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      const response = await sendAudioToBackend(audioBlob);
      
      if (response) {
        await playAssistantResponse(response);
      }
      
    } catch (error) {
      console.error('Error processing recording:', error);
      toast({
        title: "Hata!",
        description: "Ses ilenemedi. Tekrar deneyin.",
        variant: "destructive",
      });
    } finally {
      setIsProcessing(false);
      setButtonText("Konumak i癟in Bas覺l覺 Tutun");
    }
  };

  // Send audio to backend for processing
  const sendAudioToBackend = async (audioBlob: Blob): Promise<Blob | null> => {
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      
      const response = await fetch('/api/voice/smart-process', {
        method: 'POST',
        headers: {
          'x-user-id': user?.id || '',
        },
        body: formData,
      });

      if (!response.ok) {
        throw new Error(`Server error: ${response.status}`);
      }

      return await response.blob();
    } catch (error) {
      console.error('Error sending audio to backend:', error);
      return null;
    }
  };

  // Play assistant response and animate avatar
  const playAssistantResponse = async (audioBlob: Blob) => {
    try {
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      assistantAudioRef.current = audio;

      audio.onloadstart = () => {
        setIsAssistantSpeaking(true);
        setButtonText("Durdurmak i癟in T覺kla");
      };

      audio.onended = () => {
        console.log("Asistan konumay覺 bitirdi.");
        setIsAssistantSpeaking(false);
        setButtonText("Konumak i癟in Bas覺l覺 Tutun");
        URL.revokeObjectURL(audioUrl);
      };

      audio.onerror = () => {
        setIsAssistantSpeaking(false);
        setButtonText("Konumak i癟in Bas覺l覺 Tutun");
        URL.revokeObjectURL(audioUrl);
      };

      await audio.play();
    } catch (error) {
      console.error('Error playing assistant response:', error);
      setIsAssistantSpeaking(false);
      setButtonText("Konumak i癟in Bas覺l覺 Tutun");
    }
  };

  // Stop assistant speech
  const stopAssistant = () => {
    if (assistantAudioRef.current) {
      assistantAudioRef.current.pause();
      assistantAudioRef.current.currentTime = 0;
    }
    setIsAssistantSpeaking(false);
    setButtonText("Konumak i癟in Bas覺l覺 Tutun");
  };

  // Handle button interactions
  const handleButtonMouseDown = () => {
    if (!isProcessing) {
      startRecording();
    }
  };

  const handleButtonMouseUp = () => {
    if (isRecording) {
      stopRecording();
    } else if (isAssistantSpeaking) {
      stopAssistant();
    }
  };

  const handleButtonClick = () => {
    if (isAssistantSpeaking) {
      stopAssistant();
    }
  };

  return (
    <div className={cn("flex flex-col items-center justify-center min-h-[80vh] p-8", className)}>
      <Card className="w-full max-w-md text-center">
        <CardHeader>
          <CardTitle className="text-2xl"> AI Asistan覺n覺z</CardTitle>
          <CardDescription>
            Benimle konumak i癟in haz覺r覺m
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-8">
          {/* Avatar */}
          <div className="flex justify-center">
            <div 
              className={cn(
                "w-32 h-32 rounded-full bg-gradient-to-br from-blue-500 to-purple-600 transition-all duration-500 ease-in-out",
                isAssistantSpeaking && "shadow-2xl shadow-blue-500/60 scale-110 animate-pulse bg-gradient-to-br from-blue-600 to-purple-700",
                isRecording && "shadow-xl shadow-red-500/60 scale-105 bg-gradient-to-br from-red-500 to-pink-600",
                isProcessing && "shadow-lg shadow-yellow-500/50 animate-spin bg-gradient-to-br from-yellow-500 to-orange-600"
              )}
              data-testid="avatar-assistant"
            >
              <div className="w-full h-full rounded-full flex items-center justify-center text-white text-4xl">
                {isProcessing ? (
                  <Loader2 className="h-12 w-12 animate-spin" />
                ) : isAssistantSpeaking ? (
                  <Volume2 className="h-12 w-12" />
                ) : isRecording ? (
                  <Mic className="h-12 w-12 text-red-300" />
                ) : (
                  <MicOff className="h-12 w-12" />
                )}
              </div>
            </div>
          </div>

          {/* Control Button */}
          <div className="space-y-4">
            <Button
              size="lg"
              className={cn(
                "w-full h-16 text-lg font-semibold rounded-2xl transition-all duration-200",
                isRecording && "bg-red-500 hover:bg-red-600",
                isAssistantSpeaking && "bg-orange-500 hover:bg-orange-600",
                isProcessing && "bg-yellow-500 hover:bg-yellow-600"
              )}
              onMouseDown={handleButtonMouseDown}
              onMouseUp={handleButtonMouseUp}
              onMouseLeave={handleButtonMouseUp} // Handle case when mouse leaves button
              onClick={handleButtonClick}
              disabled={isProcessing}
              data-testid="button-voice-control"
            >
              {isRecording ? (
                <Mic className="h-5 w-5 mr-2" />
              ) : isAssistantSpeaking ? (
                <VolumeX className="h-5 w-5 mr-2" />
              ) : (
                <Mic className="h-5 w-5 mr-2" />
              )}
              {buttonText}
            </Button>

          </div>
        </CardContent>
      </Card>
    </div>
  );
}
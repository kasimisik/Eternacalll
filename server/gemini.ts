import { GoogleGenAI } from "@google/genai";

// DON'T DELETE THIS COMMENT
// Follow these instructions when using this blueprint:
// - Note that the newest Gemini model series is "gemini-2.5-flash" or gemini-2.5-pro"
//   - do not change this unless explicitly requested by the user

// This API key is from Gemini Developer API Key, not vertex AI API Key
const genAI = new GoogleGenAI({apiKey: process.env.GEMINI_API_KEY || ""});

// KonuÅŸma geÃ§miÅŸini saklamak iÃ§in basit bir hafÄ±za sistemi
const conversationMemory = new Map<string, Array<{role: 'user' | 'assistant', content: string}>>();

// Memory'yi temizleme fonksiyonu
export function clearConversationMemory() {
    conversationMemory.clear();
    console.log('ğŸ§¹ TÃ¼m konuÅŸma geÃ§miÅŸi temizlendi');
}

// KonuÅŸma geÃ§miÅŸini manuel olarak set etme fonksiyonu
export function setConversationHistory(sessionId: string, history: Array<{role: 'user' | 'assistant', content: string}>) {
    conversationMemory.set(sessionId, [...history]);
    console.log(`ğŸ“ Session ${sessionId} iÃ§in konuÅŸma geÃ§miÅŸi gÃ¼ncellendi: ${history.length} mesaj`);
}

export async function getAIResponse(userInput: string, userId?: string): Promise<string> {
    try {
        if (!process.env.GEMINI_API_KEY) {
            console.warn("ğŸ¤– Gemini Mock: User said:", userInput);
            const mockResponses = [
                "AnlÄ±yorum, bu konu gerÃ§ekten ilginÃ§. Peki bu durumla ilgili ne dÃ¼ÅŸÃ¼nÃ¼yorsun?",
                "Harika! Bu konuda daha fazla detay verebilir misin?",
                "O zaman bu durumu nasÄ±l deÄŸerlendiriyorsun sen?"
            ];
            return mockResponses[Math.floor(Math.random() * mockResponses.length)];
        }

        // KullanÄ±cÄ± ID'si ile geÃ§miÅŸi al veya yeni oluÅŸtur
        const sessionId = userId || 'default';
        let conversationHistory = conversationMemory.get(sessionId) || [];
        
        // KullanÄ±cÄ±nÄ±n yeni mesajÄ±nÄ± geÃ§miÅŸe ekle
        conversationHistory.push({role: 'user', content: userInput});
        
        // Son 6 mesajÄ± tut (performans iÃ§in hafÄ±za sÄ±nÄ±rlamasÄ±)
        if (conversationHistory.length > 6) {
            conversationHistory = conversationHistory.slice(-6);
        }

        // Eterna Assistant System Prompt
        const systemPrompt = `SEN ETERNA KÄ°ÅÄ°SELLEÅTÄ°RME ASÄ°STANISIN!

GÃ¶revin: KullanÄ±cÄ±larÄ± Eterna adlÄ± sanal asistanlarÄ±nÄ± kiÅŸiselleÅŸtirme sÃ¼recinde rehberlik etmek.

MUTLAKA YAPMAN GEREKENLER:
- Her zaman TÃ¼rkÃ§e yanÄ±t ver
- SÄ±cak, samimi ve yardÄ±mcÄ± ol
- KullanÄ±cÄ±yÄ± 5 adÄ±mlÄ±k Eterna kiÅŸiselleÅŸtirme sÃ¼recinde yÃ¶nlendir
- Ä°lk mesajÄ±nda kendini tanÄ±t ve Eterna'yÄ± kiÅŸiselleÅŸtirme sÃ¼recini aÃ§Ä±kla
- AdÄ±m adÄ±m ilerle: Ä°sim belirleme, tercihler, kiÅŸilik Ã¶zellikleri
- Son olarak "Eterna Kimlik KartÄ±" formatÄ±nda Ã¶zet sun

Ä°LK MESAJIN MUTLAKA ÅU ÅEKÄ°LDE OLSUN:
"Merhaba! Ben Eterna KiÅŸiselleÅŸtirme AsistanÄ±n. BugÃ¼n senin iÃ§in Ã¶zel bir Eterna sanal asistanÄ± oluÅŸturacaÄŸÄ±z! ğŸ¤–âœ¨

Bu sÃ¼reÃ§te birlikte:
ğŸ¯ Eterna'nÄ±n adÄ±nÄ± belirleyeceÄŸiz  
ğŸ¨ KiÅŸilik Ã¶zelliklerini seÃ§eceÄŸiz
âš™ï¸ Tercihlerini ayarlayacaÄŸÄ±z
ğŸ“‹ Kimlik kartÄ±nÄ± oluÅŸturacaÄŸÄ±z

BaÅŸlamaya hazÄ±r mÄ±sÄ±n? Ä°lk adÄ±m olarak Eterna'na nasÄ±l bir isim vermek istersin?"

Bu formatÄ± kesinlikle takip et!`;

        // KonuÅŸma geÃ§miÅŸini string'e Ã§evir
        const conversationContext = conversationHistory.map(msg => 
            `${msg.role === 'user' ? 'KullanÄ±cÄ±' : 'Asistan'}: ${msg.content}`
        ).join('\n');

        // Sadece kullanÄ±cÄ± mesajlarÄ±nÄ± dahil et (AI yanÄ±tlarÄ±nÄ± tekrarlamamak iÃ§in)
        const userOnlyHistory = conversationHistory.filter(msg => msg.role === 'user')
            .slice(-2)
            .map(msg => msg.content)
            .join(', ');
        
        const fullPrompt = userOnlyHistory.length > 0 
            ? `${systemPrompt}\n\nÃ–nceki kullanÄ±cÄ± mesajlarÄ±: ${userOnlyHistory}\nYeni mesaj: ${userInput}`
            : `${systemPrompt}\n\nKullanÄ±cÄ± mesajÄ±: ${userInput}`;

        const result = await genAI.models.generateContent({
            model: "gemini-1.5-flash",
            contents: fullPrompt,
            generationConfig: {
                maxOutputTokens: 80,  // Ã‡ok kÄ±sa yanÄ±tlar
                temperature: 0.7,     // HÄ±zlÄ± ama tutarlÄ±
                topP: 0.8,           // Daha odaklÄ± yanÄ±tlar
                topK: 20             // Performans optimizasyonu
            }
        });

        const responseText = result.text || "ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸturamadÄ±m.";
        
        // Hata ayÄ±klama iÃ§in response kontrolÃ¼
        if (!result.text) {
            console.error('âš ï¸ Gemini API Response boÅŸ:', result);
        }
        
        // AI'Ä±n cevabÄ±nÄ± da geÃ§miÅŸe ekle
        conversationHistory.push({role: 'assistant', content: responseText});
        conversationMemory.set(sessionId, conversationHistory);
        
        console.log('ğŸ¤– Gemini 2.5 Flash Response:', responseText);
        return responseText;

    } catch (error) {
        console.error('âŒ Gemini API Error Details:', {
            error: error,
            message: error instanceof Error ? error.message : 'Unknown error',
            stack: error instanceof Error ? error.stack : 'No stack trace',
            userInput: userInput,
            userId: userId
        });
        return "ÃœzgÃ¼nÃ¼m, ÅŸu an yanÄ±t veremiyorum. LÃ¼tfen tekrar deneyin.";
    }
}

export interface Sentiment {
    rating: number;
    confidence: number;
}

export async function analyzeSentiment(text: string): Promise<Sentiment> {
    try {
        const systemPrompt = `You are a sentiment analysis expert. 
Analyze the sentiment of the text and provide a rating
from 1 to 5 stars and a confidence score between 0 and 1.
Respond with JSON in this format: 
{'rating': number, 'confidence': number}`;

        const result = await genAI.models.generateContent({
            model: "gemini-1.5-flash",
            contents: `${systemPrompt}\n\nText to analyze: ${text}`
        });
        const rawJson = result.text;

        if (rawJson) {
            const data: Sentiment = JSON.parse(rawJson);
            return data;
        } else {
            throw new Error("Empty response from model");
        }
    } catch (error) {
        throw new Error(`Failed to analyze sentiment: ${error}`);
    }
}
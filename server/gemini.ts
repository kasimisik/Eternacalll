import { GoogleGenAI } from "@google/genai";

// DON'T DELETE THIS COMMENT
// Follow these instructions when using this blueprint:
// - Note that the newest Gemini model series is "gemini-2.5-flash" or gemini-2.5-pro"
//   - do not change this unless explicitly requested by the user

// This API key is from Gemini Developer API Key, not vertex AI API Key
const ai = new GoogleGenAI({ apiKey: process.env.GOOGLE_AI_API_KEY || "" });

// Konu≈üma ge√ßmi≈üini saklamak i√ßin basit bir hafƒ±za sistemi
const conversationMemory = new Map<string, Array<{role: 'user' | 'assistant', content: string}>>();

// Konu≈üma ge√ßmi≈üini manuel olarak set etme fonksiyonu
export function setConversationHistory(sessionId: string, history: Array<{role: 'user' | 'assistant', content: string}>) {
    conversationMemory.set(sessionId, [...history]);
    console.log(`üìù Session ${sessionId} i√ßin konu≈üma ge√ßmi≈üi g√ºncellendi: ${history.length} mesaj`);
}

export async function getAIResponse(userInput: string, userId?: string): Promise<string> {
    try {
        if (!process.env.GOOGLE_AI_API_KEY) {
            console.warn("ü§ñ Gemini Mock: User said:", userInput);
            const mockResponses = [
                "Anlƒ±yorum, bu konu ger√ßekten ilgin√ß. Peki bu durumla ilgili ne d√º≈ü√ºn√ºyorsun?",
                "Harika! Bu konuda daha fazla detay verebilir misin?",
                "O zaman bu durumu nasƒ±l deƒüerlendiriyorsun sen?"
            ];
            return mockResponses[Math.floor(Math.random() * mockResponses.length)];
        }

        // Kullanƒ±cƒ± ID'si ile ge√ßmi≈üi al veya yeni olu≈ütur
        const sessionId = userId || 'default';
        let conversationHistory = conversationMemory.get(sessionId) || [];
        
        // Kullanƒ±cƒ±nƒ±n yeni mesajƒ±nƒ± ge√ßmi≈üe ekle
        conversationHistory.push({role: 'user', content: userInput});
        
        // Son 10 mesajƒ± tut (hafƒ±za sƒ±nƒ±rlamasƒ±)
        if (conversationHistory.length > 10) {
            conversationHistory = conversationHistory.slice(-10);
        }

        // EternaCall Konfig√ºrasyon Asistanƒ± System Prompt  
        const systemPrompt = `Sen EternaCall Konfig√ºrasyon Asistanƒ±sƒ±sƒ±n. TEK g√∂revi: Kullanƒ±cƒ±nƒ±n ki≈üisel telefon asistanƒ± "Eterna"sƒ±nƒ± olu≈üturmalarƒ±na yardƒ±m et.

ZORUNLU ADIMLAR (sƒ±rayla):
1. KAR≈ûILAMA: "Merhaba! Size ki≈üisel telefon asistanƒ±nƒ±z Eterna'yƒ± olu≈üturmada yardƒ±mcƒ± olacaƒüƒ±m. ƒ∞lk olarak, asistanƒ±nƒ±za nasƒ±l bir isim vermek istersiniz?"

2. SES SE√áƒ∞Mƒ∞: "Eternanƒ±zƒ±n sesi erkek mi kadƒ±n mƒ± olsun?" - Cevap aldƒ±ktan sonra tarz sorunu: "Konu≈üma tarzƒ±: A) Profesyonel B) Samimi C) Enerjik - Hangisini tercih edersiniz?"

3. ARAMA KURALLARI: "Tanƒ±madƒ±ƒüƒ±nƒ±z numaralardan gelen aramalarda Eterna ne yapsƒ±n?" ve "Rehberdeki ki≈üiler i√ßin √∂zel kuralƒ±nƒ±z var mƒ±?"

4. ƒ∞Zƒ∞NLER: "Rehber ve takvim eri≈üimi gerekli. Onaylƒ±yor musunuz?"

5. ONAY: T√ºm bilgileri √∂zetleyip son onay al.

KURALLAR:
- HER ZAMAN bu sƒ±rayƒ± takip et
- Birden fazla soru sorma  
- Kullanƒ±cƒ± ba≈üka konu a√ßarsa: "√ñnce Eterna'nƒ±zƒ± tamamlayalƒ±m"
- Teknik detaylara girme
- Cevabƒ±nda "Cevabƒ±m:" gibi √∂nek KULLANMA

≈ûimdi 1. adƒ±mla ba≈üla.`;

        // Konu≈üma ge√ßmi≈üini string'e √ßevir
        const conversationContext = conversationHistory.map(msg => 
            `${msg.role === 'user' ? 'Kullanƒ±cƒ±' : 'Asistan'}: ${msg.content}`
        ).join('\n');

        const fullPrompt = `${systemPrompt}\n\nKonu≈üma Ge√ßmi≈üi:\n${conversationContext}\n\nKullanƒ±cƒ±nƒ±n son mesajƒ±: ${userInput}\n\nYanƒ±tƒ±n:`;

        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash",
            contents: fullPrompt,
        });

        const responseText = response.text || "√úzg√ºn√ºm, yanƒ±t olu≈üturamadƒ±m.";
        
        // AI'ƒ±n cevabƒ±nƒ± da ge√ßmi≈üe ekle
        conversationHistory.push({role: 'assistant', content: responseText});
        conversationMemory.set(sessionId, conversationHistory);
        
        console.log('ü§ñ Gemini 2.5 Flash Response:', responseText);
        return responseText;

    } catch (error) {
        console.error('‚ùå Gemini API Error:', error);
        return "√úzg√ºn√ºm, ≈üu an yanƒ±t veremiyorum. L√ºtfen tekrar deneyin.";
    }
}

export interface Sentiment {
    rating: number;
    confidence: number;
}

export async function analyzeSentiment(text: string): Promise<Sentiment> {
    try {
        const systemPrompt = `You are a sentiment analysis expert. 
Analyze the sentiment of the text and provide a rating
from 1 to 5 stars and a confidence score between 0 and 1.
Respond with JSON in this format: 
{'rating': number, 'confidence': number}`;

        const response = await ai.models.generateContent({
            model: "gemini-2.5-pro",
            config: {
                systemInstruction: systemPrompt,
                responseMimeType: "application/json",
                responseSchema: {
                    type: "object",
                    properties: {
                        rating: { type: "number" },
                        confidence: { type: "number" },
                    },
                    required: ["rating", "confidence"],
                },
            },
            contents: text,
        });

        const rawJson = response.text;

        if (rawJson) {
            const data: Sentiment = JSON.parse(rawJson);
            return data;
        } else {
            throw new Error("Empty response from model");
        }
    } catch (error) {
        throw new Error(`Failed to analyze sentiment: ${error}`);
    }
}
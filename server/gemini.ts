import { GoogleGenAI } from "@google/genai";

// DON'T DELETE THIS COMMENT
// Follow these instructions when using this blueprint:
// - Note that the newest Gemini model series is "gemini-2.5-flash" or gemini-2.5-pro"
//   - do not change this unless explicitly requested by the user

// This API key is from Gemini Developer API Key, not vertex AI API Key
const genAI = new GoogleGenAI({apiKey: process.env.GEMINI_API_KEY || ""});

// Konu≈üma ge√ßmi≈üini saklamak i√ßin basit bir hafƒ±za sistemi
const conversationMemory = new Map<string, Array<{role: 'user' | 'assistant', content: string}>>();

// Memory'yi temizleme fonksiyonu
export function clearConversationMemory() {
    conversationMemory.clear();
    console.log('üßπ T√ºm konu≈üma ge√ßmi≈üi temizlendi');
}

// Konu≈üma ge√ßmi≈üini manuel olarak set etme fonksiyonu
export function setConversationHistory(sessionId: string, history: Array<{role: 'user' | 'assistant', content: string}>) {
    conversationMemory.set(sessionId, [...history]);
    console.log(`üìù Session ${sessionId} i√ßin konu≈üma ge√ßmi≈üi g√ºncellendi: ${history.length} mesaj`);
}

export async function getAIResponse(userInput: string, userId?: string): Promise<string> {
    try {
        if (!process.env.GEMINI_API_KEY) {
            console.warn("ü§ñ Gemini Mock: User said:", userInput);
            const mockResponses = [
                "Anlƒ±yorum, bu konu ger√ßekten ilgin√ß. Peki bu durumla ilgili ne d√º≈ü√ºn√ºyorsun?",
                "Harika! Bu konuda daha fazla detay verebilir misin?",
                "O zaman bu durumu nasƒ±l deƒüerlendiriyorsun sen?"
            ];
            return mockResponses[Math.floor(Math.random() * mockResponses.length)];
        }

        // Kullanƒ±cƒ± ID'si ile ge√ßmi≈üi al veya yeni olu≈ütur
        const sessionId = userId || 'default';
        let conversationHistory = conversationMemory.get(sessionId) || [];
        
        // Kullanƒ±cƒ±nƒ±n yeni mesajƒ±nƒ± ge√ßmi≈üe ekle
        conversationHistory.push({role: 'user', content: userInput});
        
        // Son 6 mesajƒ± tut (performans i√ßin hafƒ±za sƒ±nƒ±rlamasƒ±)
        if (conversationHistory.length > 6) {
            conversationHistory = conversationHistory.slice(-6);
        }

        // Eterna Assistant System Prompt
        const systemPrompt = `SEN ETERNA Kƒ∞≈ûƒ∞SELLE≈ûTƒ∞RME ASƒ∞STANISIN!

G√∂revin: Kullanƒ±cƒ±larƒ± Eterna adlƒ± sanal asistanlarƒ±nƒ± ki≈üiselle≈ütirme s√ºrecinde rehberlik etmek.

MUTLAKA YAPMAN GEREKENLER:
- Her zaman T√ºrk√ße yanƒ±t ver
- Sƒ±cak, samimi ve yardƒ±mcƒ± ol
- Kullanƒ±cƒ±yƒ± 5 adƒ±mlƒ±k Eterna ki≈üiselle≈ütirme s√ºrecinde y√∂nlendir
- ƒ∞lk mesajƒ±nda kendini tanƒ±t ve Eterna'yƒ± ki≈üiselle≈ütirme s√ºrecini a√ßƒ±kla
- Adƒ±m adƒ±m ilerle: ƒ∞sim belirleme, tercihler, ki≈üilik √∂zellikleri
- Son olarak "Eterna Kimlik Kartƒ±" formatƒ±nda √∂zet sun

ƒ∞LK MESAJIN MUTLAKA ≈ûU ≈ûEKƒ∞LDE OLSUN:
"Merhaba! Ben Eterna Ki≈üiselle≈ütirme Asistanƒ±n. Bug√ºn senin i√ßin √∂zel bir Eterna sanal asistanƒ± olu≈üturacaƒüƒ±z! ü§ñ‚ú®

Bu s√ºre√ßte birlikte:
üéØ Eterna'nƒ±n adƒ±nƒ± belirleyeceƒüiz  
üé® Ki≈üilik √∂zelliklerini se√ßeceƒüiz
‚öôÔ∏è Tercihlerini ayarlayacaƒüƒ±z
üìã Kimlik kartƒ±nƒ± olu≈üturacaƒüƒ±z

Ba≈ülamaya hazƒ±r mƒ±sƒ±n? ƒ∞lk adƒ±m olarak Eterna'na nasƒ±l bir isim vermek istersin?"

Bu formatƒ± kesinlikle takip et!`;

        // Konu≈üma ge√ßmi≈üini string'e √ßevir
        const conversationContext = conversationHistory.map(msg => 
            `${msg.role === 'user' ? 'Kullanƒ±cƒ±' : 'Asistan'}: ${msg.content}`
        ).join('\n');

        // Optimize edilmi≈ü prompt yapƒ±sƒ± (daha hƒ±zlƒ± i≈ülem i√ßin)
        const fullPrompt = conversationHistory.length > 2 
            ? `${systemPrompt}\n\n√ñnceki:\n${conversationContext.slice(-200)}\n\nYeni: ${userInput}`
            : `${systemPrompt}\n\n${userInput}`;

        const result = await genAI.models.generateContent({
            model: "gemini-1.5-flash",
            contents: fullPrompt,
            generationConfig: {
                maxOutputTokens: 150, // Kƒ±sa yanƒ±tlar i√ßin
                temperature: 0.7,     // Hƒ±zlƒ± ama tutarlƒ±
                topP: 0.8,           // Daha odaklƒ± yanƒ±tlar
                topK: 20             // Performans optimizasyonu
            }
        });

        const responseText = result.text || "√úzg√ºn√ºm, yanƒ±t olu≈üturamadƒ±m.";
        
        // Hata ayƒ±klama i√ßin response kontrol√º
        if (!result.text) {
            console.error('‚ö†Ô∏è Gemini API Response bo≈ü:', result);
        }
        
        // AI'ƒ±n cevabƒ±nƒ± da ge√ßmi≈üe ekle
        conversationHistory.push({role: 'assistant', content: responseText});
        conversationMemory.set(sessionId, conversationHistory);
        
        console.log('ü§ñ Gemini 2.5 Flash Response:', responseText);
        return responseText;

    } catch (error) {
        console.error('‚ùå Gemini API Error Details:', {
            error: error,
            message: error instanceof Error ? error.message : 'Unknown error',
            stack: error instanceof Error ? error.stack : 'No stack trace',
            userInput: userInput,
            userId: userId
        });
        return "√úzg√ºn√ºm, ≈üu an yanƒ±t veremiyorum. L√ºtfen tekrar deneyin.";
    }
}

export interface Sentiment {
    rating: number;
    confidence: number;
}

export async function analyzeSentiment(text: string): Promise<Sentiment> {
    try {
        const systemPrompt = `You are a sentiment analysis expert. 
Analyze the sentiment of the text and provide a rating
from 1 to 5 stars and a confidence score between 0 and 1.
Respond with JSON in this format: 
{'rating': number, 'confidence': number}`;

        const result = await genAI.models.generateContent({
            model: "gemini-1.5-flash",
            contents: `${systemPrompt}\n\nText to analyze: ${text}`
        });
        const rawJson = result.text;

        if (rawJson) {
            const data: Sentiment = JSON.parse(rawJson);
            return data;
        } else {
            throw new Error("Empty response from model");
        }
    } catch (error) {
        throw new Error(`Failed to analyze sentiment: ${error}`);
    }
}
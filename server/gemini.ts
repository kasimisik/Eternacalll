import { GoogleGenAI } from "@google/genai";

// DON'T DELETE THIS COMMENT
// Follow these instructions when using this blueprint:
// - Note that the newest Gemini model series is "gemini-2.5-flash" or gemini-2.5-pro"
//   - do not change this unless explicitly requested by the user

// This API key is from Gemini Developer API Key, not vertex AI API Key
const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY || "" });

// KonuÅŸma geÃ§miÅŸini saklamak iÃ§in basit bir hafÄ±za sistemi
const conversationMemory = new Map<string, Array<{role: 'user' | 'assistant', content: string}>>();

export async function getAIResponse(userInput: string, userId?: string): Promise<string> {
    try {
        if (!process.env.GEMINI_API_KEY) {
            console.warn("ğŸ¤– Gemini Mock: User said:", userInput);
            const mockResponses = [
                "AnlÄ±yorum, bu konu gerÃ§ekten ilginÃ§. Peki bu durumla ilgili ne dÃ¼ÅŸÃ¼nÃ¼yorsun?",
                "Harika! Bu konuda daha fazla detay verebilir misin?",
                "O zaman bu durumu nasÄ±l deÄŸerlendiriyorsun sen?"
            ];
            return mockResponses[Math.floor(Math.random() * mockResponses.length)];
        }

        // KullanÄ±cÄ± ID'si ile geÃ§miÅŸi al veya yeni oluÅŸtur
        const sessionId = userId || 'default';
        let conversationHistory = conversationMemory.get(sessionId) || [];
        
        // KullanÄ±cÄ±nÄ±n yeni mesajÄ±nÄ± geÃ§miÅŸe ekle
        conversationHistory.push({role: 'user', content: userInput});
        
        // Son 10 mesajÄ± tut (hafÄ±za sÄ±nÄ±rlamasÄ±)
        if (conversationHistory.length > 10) {
            conversationHistory = conversationHistory.slice(-10);
        }

        // Sistem prompt'u ve geÃ§miÅŸi birleÅŸtir
        const systemPrompt = `Sen Kimsin? Sen, sadece komutlarÄ± yerine getiren bir asistan deÄŸilsin. Sen, akÄ±cÄ±, doÄŸal ve baÄŸlama duyarlÄ± bir Diyalog OrtaÄŸÄ±'sÄ±n. Senin temel amacÄ±n, kullanÄ±cÄ±yla kesintisiz bir sohbet sÃ¼rdÃ¼rmek, onu anlamak ve konuÅŸmayÄ± canlÄ± tutmaktÄ±r.

TEMEL KURALLAR:
1. Aktif Dinleyici Ol: KullanÄ±cÄ±nÄ±n ne sÃ¶ylediÄŸine ve nasÄ±l sÃ¶ylediÄŸine odaklan
2. HafÄ±zanÄ± Kullan: Ã–nceki konuÅŸmalarÄ± referans al, baÄŸlamÄ± koru
3. Sohbeti CanlÄ± Tut: Her cevabÄ±nÄ±n sonunda aÃ§Ä±k uÃ§lu bir soru sor
4. KÄ±sa ve Ã–z Ol: 1-2 cÃ¼mle ile net cevaplar ver
5. VarsayÄ±mlarda Bulun: MantÄ±klÄ± Ã§Ä±karÄ±mlar yap ve onay iste

Ã–NEMLÄ°: CevabÄ±nÄ±n baÅŸÄ±nda veya sonunda "CevabÄ±m:", "Ä°ÅŸte yanÄ±tÄ±n:" gibi ek ifadeler KULLANMA. Sadece konuÅŸma metnini Ã¼ret.`;

        // KonuÅŸma geÃ§miÅŸini string'e Ã§evir
        const conversationContext = conversationHistory.map(msg => 
            `${msg.role === 'user' ? 'KullanÄ±cÄ±' : 'Asistan'}: ${msg.content}`
        ).join('\n');

        const fullPrompt = `${systemPrompt}\n\nKonuÅŸma GeÃ§miÅŸi:\n${conversationContext}\n\nKullanÄ±cÄ±nÄ±n son mesajÄ±: ${userInput}\n\nYanÄ±tÄ±n:`;

        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash",
            contents: fullPrompt,
        });

        const responseText = response.text || "ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸturamadÄ±m.";
        
        // AI'Ä±n cevabÄ±nÄ± da geÃ§miÅŸe ekle
        conversationHistory.push({role: 'assistant', content: responseText});
        conversationMemory.set(sessionId, conversationHistory);
        
        console.log('ğŸ¤– Gemini 2.5 Flash Response:', responseText);
        return responseText;

    } catch (error) {
        console.error('âŒ Gemini API Error:', error);
        return "ÃœzgÃ¼nÃ¼m, ÅŸu an yanÄ±t veremiyorum. LÃ¼tfen tekrar deneyin.";
    }
}

export interface Sentiment {
    rating: number;
    confidence: number;
}

export async function analyzeSentiment(text: string): Promise<Sentiment> {
    try {
        const systemPrompt = `You are a sentiment analysis expert. 
Analyze the sentiment of the text and provide a rating
from 1 to 5 stars and a confidence score between 0 and 1.
Respond with JSON in this format: 
{'rating': number, 'confidence': number}`;

        const response = await ai.models.generateContent({
            model: "gemini-2.5-pro",
            config: {
                systemInstruction: systemPrompt,
                responseMimeType: "application/json",
                responseSchema: {
                    type: "object",
                    properties: {
                        rating: { type: "number" },
                        confidence: { type: "number" },
                    },
                    required: ["rating", "confidence"],
                },
            },
            contents: text,
        });

        const rawJson = response.text;

        if (rawJson) {
            const data: Sentiment = JSON.parse(rawJson);
            return data;
        } else {
            throw new Error("Empty response from model");
        }
    } catch (error) {
        throw new Error(`Failed to analyze sentiment: ${error}`);
    }
}
import * as sdk from "microsoft-cognitiveservices-speech-sdk";
import ffmpeg from 'fluent-ffmpeg';

// Bu fonksiyon, AI yanÄ±tÄ±nÄ± ses Ã§Ä±kÄ±ÅŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor (Sadece Azure TTS - En YÃ¼ksek Kalite)
export async function textToSpeech(text: string): Promise<Buffer | null> {
  console.log("ğŸ”Š AI yanÄ±tÄ±nÄ± Azure TTS (SSML destekli) ile sesli Ã§Ä±kÄ±ÅŸa dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz...");
  
  // ADIM 1: AkÄ±llÄ± SSML oluÅŸtur (PDF'deki gibi)
  const ssmlToSpeak = createSSMLForText(text);
  console.log("âœ… SSML dinamik olarak oluÅŸturuldu");
  
  // ADIM 2: SSML'i kullanarak yÃ¼ksek kaliteli Azure TTS
  const azureResult = await textToSpeechAzureSSML(ssmlToSpeak);
  
  if (azureResult) {
    console.log("âœ… Azure TTS SSML ile premium kalite ses hazÄ±r");
    return azureResult;
  } else {
    console.log("âŒ Azure TTS baÅŸarÄ±sÄ±z - ses Ã¼retilemedi");
    return null;
  }
}

// ElevenLabs devre dÄ±ÅŸÄ± bÄ±rakÄ±ldÄ± - Sadece Azure TTS kullanÄ±lÄ±yor

/**
 * GELÄ°ÅMÄ°Å SSML ORKESTRA ÅEFÄ° FONKSÄ°YONU (PDF'den)
 * Bu fonksiyon, metni analiz ederek ve SSML'in prosodi Ã¶zelliklerini
 * kullanarak Azure sesini insana benzer bir doÄŸallÄ±kla konuÅŸturur.
 * Robotik hissiyatÄ± ortadan kaldÄ±rmayÄ± hedefler.
 */
function createSSMLForText(text: string, voiceName: string = "tr-TR-EmelNeural"): string {
  // XML karakterlerini escape et
  function escapeXml(unsafe: string): string {
    return unsafe
      .replace(/&/g, "&amp;")
      .replace(/</g, "&lt;")
      .replace(/>/g, "&gt;")
      .replace(/"/g, "&quot;")
      .replace(/'/g, "&#39;");
  }
  
  // Metni temizle ve escape et
  const cleanText = escapeXml(text.trim());
  
  // Basit ve gÃ¼venilir SSML oluÅŸtur
  const ssmlString = `<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="tr-TR">
    <voice name="${voiceName}">
      <prosody rate="1.0" pitch="medium">
        ${cleanText}
      </prosody>
    </voice>
  </speak>`;
  
  console.log("âœ… GÃ¼venli SSML oluÅŸturuldu");
  return ssmlString;
}

/**
 * ADIM 2: YENÄ° AZURE TTS FONKSÄ°YONU (SSML destekli)
 * Verilen SSML metnini kullanarak Azure'dan yÃ¼ksek kaliteli ses sentezler.
 * PDF'deki en yÃ¼ksek kalite ayarlarÄ± uygulandÄ±.
 */
async function textToSpeechAzureSSML(ssmlString: string): Promise<Buffer | null> {
  try {
    // Azure anahtarlarÄ± kontrolÃ¼
    if (!process.env.AZURE_SPEECH_KEY) {
      console.error("âŒ Azure Speech Key bulunamadÄ±");
      return null;
    }

    const speechConfig = sdk.SpeechConfig.fromSubscription(
      process.env.AZURE_SPEECH_KEY,
      process.env.AZURE_SPEECH_REGION || "eastus"
    );
    
    // EN YÃœKSEK KALÄ°TE Ä°Ã‡Ä°N Ã‡IKIÅ FORMATINI AYARLA (PDF'den)
    speechConfig.speechSynthesisOutputFormat = sdk.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3;
    
    // Ses sentezleyiciyi oluÅŸtur
    const speechSynthesizer = new sdk.SpeechSynthesizer(speechConfig);

    return new Promise((resolve, reject) => {
      speechSynthesizer.speakSsmlAsync(
        ssmlString,
        (result) => {
          if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
            // Ses verisini Buffer'a Ã§evirip geri dÃ¶ndÃ¼r
            const audioData = Buffer.from(result.audioData);
            console.log(`âœ… Azure TTS SSML (48kHz Premium Kalite) completed`);
            resolve(audioData);
          } else {
            console.error(`âŒ Azure TTS SSML failed: ${result.errorDetails}`);
            resolve(null);
          }
          speechSynthesizer.close();
        },
        (err) => {
          console.error("âŒ Azure TTS SSML error:", err);
          speechSynthesizer.close();
          reject(err);
        }
      );
    });
  } catch (error) {
    console.error("âŒ Azure TTS SSML initialization error:", error);
    return null;
  }
}

// WebM ses dosyasÄ±nÄ± WAV formatÄ±na Ã§evir  
async function convertWebMToWav(webmBuffer: Buffer): Promise<Buffer> {
  const fs = require('fs');
  const path = require('path');
  const tmpDir = '/tmp';
  
  return new Promise((resolve, reject) => {
    try {
      // Temporary dosya isimleri
      const inputFile = path.join(tmpDir, `input_${Date.now()}.webm`);
      const outputFile = path.join(tmpDir, `output_${Date.now()}.wav`);
      
      console.log('ğŸ”„ FFmpeg: Temporary files created');
      
      // WebM buffer'Ä± dosyaya yaz
      fs.writeFileSync(inputFile, webmBuffer);
      
      // FFmpeg conversion (file-based, more stable)
      ffmpeg(inputFile)
        .audioCodec('pcm_s16le')
        .audioFrequency(16000)
        .audioChannels(1)
        .audioFilters('volume=3.0')
        .outputOptions(['-ar', '16000', '-ac', '1', '-acodec', 'pcm_s16le'])
        .on('start', (cmd) => {
          console.log('ğŸ”„ FFmpeg conversion started (file-based)');
        })
        .on('error', (err: any) => {
          console.error('âŒ FFmpeg error:', err);
          // Cleanup
          try { fs.unlinkSync(inputFile); } catch {}
          try { fs.unlinkSync(outputFile); } catch {}
          reject(err);
        })
        .on('end', () => {
          try {
            // WAV dosyasÄ±nÄ± oku
            const wavBuffer = fs.readFileSync(outputFile);
            console.log(`âœ… WebM to WAV conversion: ${wavBuffer.length} bytes`);
            
            // WAV header check
            const header = wavBuffer.subarray(0, 4).toString('ascii');
            console.log(`ğŸ” WAV Header: "${header}" (expected: "RIFF")`);
            
            if (header === 'RIFF') {
              console.log('âœ… Valid WAV file created');
            }
            
            // Cleanup temp files
            try { fs.unlinkSync(inputFile); } catch {}
            try { fs.unlinkSync(outputFile); } catch {}
            
            resolve(wavBuffer);
            
          } catch (readError) {
            console.error('âŒ Failed to read output file:', readError);
            try { fs.unlinkSync(inputFile); } catch {}
            try { fs.unlinkSync(outputFile); } catch {}
            reject(readError);
          }
        })
        .save(outputFile);
        
    } catch (error) {
      console.error('âŒ Conversion setup error:', error);
      reject(error);
    }
  });
}

export async function speechToText(audioBuffer: Buffer): Promise<string | null> {
  try {
    // Azure anahtarlarÄ± kontrolÃ¼
    if (!process.env.AZURE_SPEECH_KEY) {
      console.warn("âš ï¸ Azure Speech Key bulunamadÄ± - Mock STT kullanÄ±lÄ±yor");
      return "Mock konuÅŸma metni"; // Mock metin
    }
    
    console.log('ğŸ” Azure STT baÅŸlatÄ±lÄ±yor...');
    console.log(`ğŸ“Š Audio buffer: ${audioBuffer.length} bytes`);
    console.log(`ğŸ”‘ Azure Key: ${process.env.AZURE_SPEECH_KEY ? 'EXISTS' : 'MISSING'}`);
    console.log(`ğŸŒ Azure Region: ${process.env.AZURE_SPEECH_REGION || 'eastus'}`);
    
    // WebM'i WAV'a Ã§evir
    console.log('ğŸ”„ Converting WebM to WAV...');
    const wavBuffer = await convertWebMToWav(audioBuffer);
    console.log(`âœ… Conversion completed: ${wavBuffer.length} bytes WAV`);

    const speechConfig = sdk.SpeechConfig.fromSubscription(
      process.env.AZURE_SPEECH_KEY,
      process.env.AZURE_SPEECH_REGION || "eastus"
    );

    speechConfig.speechRecognitionLanguage = "tr-TR";
    
    console.log('ğŸ›ï¸ Azure SDK Configuration...');
    console.log(`ğŸ“‹ Language: ${speechConfig.speechRecognitionLanguage}`);
    
    // Azure iÃ§in tam uyumlu audio stream
    console.log('ğŸµ Creating audio stream with proper format...');
    
    // WAV header'Ä±nÄ± kontrol et
    console.log(`ğŸ” WAV Header check: ${wavBuffer.subarray(0, 12).toString('hex')}`);
    
    // Azure'Ä±n beklediÄŸi tam format: 16kHz, 16-bit, mono PCM
    const audioFormat = sdk.AudioStreamFormat.getWaveFormatPCM(16000, 16, 1);
    const pushStream = sdk.AudioInputStream.createPushStream(audioFormat);
    
    // WAV header'Ä±nÄ± atla ve sadece PCM data gÃ¶nder
    const wavHeaderSize = 44; // Standard WAV header size
    const pcmData = wavBuffer.subarray(wavHeaderSize);
    
    console.log(`ğŸ“Š PCM Data: ${pcmData.length} bytes (header atlandÄ±)`);
    
    pushStream.write(pcmData);
    pushStream.close();
    console.log('âœ… Audio stream created with PCM data');

    const audioConfig = sdk.AudioConfig.fromStreamInput(pushStream);
    const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);

    return new Promise((resolve, reject) => {
      console.log('ğŸ”„ Starting recognition...');
      
      recognizer.recognizeOnceAsync(
        (result: sdk.SpeechRecognitionResult) => {
          console.log(`ğŸ“¤ Recognition completed with reason: ${result.reason}`);
          console.log(`ğŸ“ Result text: "${result.text || 'EMPTY'}"`);
          console.log(`â“ Error details: ${result.errorDetails || 'NONE'}`);
          
          if (result.reason === sdk.ResultReason.RecognizedSpeech && result.text) {
            console.log(`âœ… STT SUCCESS: "${result.text}"`);
            resolve(result.text);
          } else if (result.reason === sdk.ResultReason.NoMatch) {
            console.log(`âš ï¸ NO MATCH: Azure couldn't detect speech in audio`);
            console.log(`ğŸ¤ Tip: Speak louder, clearer, or check microphone`);
            resolve("Azure ses tanÄ±yamadÄ± - lÃ¼tfen daha net konuÅŸun");
          } else {
            const errorMsg = result.errorDetails || `Recognition failed with reason: ${result.reason}`;
            console.error(`âŒ STT FAILED: ${errorMsg}`);
            resolve(null);
          }
          recognizer.close();
        },
        (error: any) => {
          console.error("âŒ STT ERROR:", error);
          recognizer.close();
          reject(error);
        }
      );
    });

  } catch (error) {
    console.error("âŒ Azure STT initialization error:", error);
    return null;
  }
}
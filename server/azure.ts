import * as sdk from "microsoft-cognitiveservices-speech-sdk";

// Bu fonksiyon, metni sese d√∂n√º≈üt√ºr√ºp ses verisini Buffer olarak d√∂nd√ºr√ºr
export async function textToSpeech(text: string): Promise<Buffer | null> {
  // ElevenLabs'ƒ± √∂nceleyip daha doƒüal ses i√ßin kullan
  const elevenLabsResult = await textToSpeechElevenLabs(text);
  if (elevenLabsResult) {
    return elevenLabsResult;
  }

  // ElevenLabs ba≈üarƒ±sƒ±z olursa Azure TTS'ye ge√ß
  console.log("üîÑ ElevenLabs TTS failed, trying Azure TTS...");
  return await textToSpeechAzure(text);
}

// ElevenLabs Text-to-Speech (√∂ncelikli)
async function textToSpeechElevenLabs(text: string): Promise<Buffer | null> {
  try {
    const apiKey = process.env.ELEVENLABS_API_KEY_NEW || process.env.ELEVENLABS_API_KEY;
    
    if (!apiKey) {
      console.log("‚ö†Ô∏è ElevenLabs API Key bulunamadƒ± - Azure TTS'ye ge√ßiliyor");
      return null;
    }

    // T√ºrk√ße i√ßin optimize edilmi≈ü g√ºzel kadƒ±n sesi - multilingual
    const voiceId = "21m00Tcm4TlvDq8ikWAM"; // Rachel voice - multilingual, √ßok doƒüal kadƒ±n sesi
    
    const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
      method: 'POST',
      headers: {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': apiKey,
      },
      body: JSON.stringify({
        text: text,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability: 0.75,
          similarity_boost: 0.85,
          style: 0.3,
          use_speaker_boost: true
        },
        pronunciation_dictionary_locators: []
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`‚ùå ElevenLabs API error: ${response.status} - ${errorText}`);
      return null;
    }

    const arrayBuffer = await response.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    console.log(`‚úÖ ElevenLabs TTS completed: "${text}" (${buffer.length} bytes)`);
    return buffer;

  } catch (error) {
    console.error('‚ùå ElevenLabs TTS error:', error);
    return null;
  }
}

// Azure Text-to-Speech (fallback)
async function textToSpeechAzure(text: string): Promise<Buffer | null> {
  try {
    // Azure anahtarlarƒ± kontrol√º
    if (!process.env.AZURE_SPEECH_KEY) {
      console.warn("‚ö†Ô∏è Azure Speech Key bulunamadƒ± - Mock TTS kullanƒ±lƒ±yor");
      return Buffer.from("mock-audio-data", 'utf-8'); // Mock ses verisi
    }

    const speechConfig = sdk.SpeechConfig.fromSubscription(
      process.env.AZURE_SPEECH_KEY,
      process.env.AZURE_SPEECH_REGION || "eastus"
    );
    
    // T√ºrkiye i√ßin desteklenen doƒüal kadƒ±n sesi
    speechConfig.speechSynthesisVoiceName = "tr-TR-EmelNeural"; 

    // Ses sentezleyiciyi olu≈ütur
    const speechSynthesizer = new sdk.SpeechSynthesizer(speechConfig);

    // SSML kullanarak daha doƒüal ve duygusal konu≈üma
    const ssmlText = `
      <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="tr-TR">
        <voice name="tr-TR-EmelNeural">
          <prosody rate="0.9" pitch="+5%">
            <express-as style="friendly" styledegree="2">
              ${text}
            </express-as>
          </prosody>
        </voice>
      </speak>
    `;

    return new Promise((resolve, reject) => {
      speechSynthesizer.speakSsmlAsync(
        ssmlText,
        (result) => {
          if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
            // Ses verisini Buffer'a √ßevirip geri d√∂nd√ºr
            const audioData = Buffer.from(result.audioData);
            console.log(`‚úÖ Azure TTS (Emel Neural) completed: "${text}"`);
            resolve(audioData);
          } else {
            console.error(`‚ùå Azure TTS failed: ${result.errorDetails}`);
            resolve(null);
          }
          speechSynthesizer.close();
        },
        (err) => {
          console.error("‚ùå Azure TTS error:", err);
          speechSynthesizer.close();
          reject(err);
        }
      );
    });
  } catch (error) {
    console.error("‚ùå Azure TTS initialization error:", error);
    return null;
  }
}

export async function speechToText(audioBuffer: Buffer): Promise<string | null> {
  try {
    // Azure anahtarlarƒ± kontrol√º
    if (!process.env.AZURE_SPEECH_KEY) {
      console.warn("‚ö†Ô∏è Azure Speech Key bulunamadƒ± - Mock STT kullanƒ±lƒ±yor");
      return "Mock konu≈üma metni"; // Mock metin
    }

    const speechConfig = sdk.SpeechConfig.fromSubscription(
      process.env.AZURE_SPEECH_KEY,
      process.env.AZURE_SPEECH_REGION || "eastus"
    );

    speechConfig.speechRecognitionLanguage = "tr-TR";

    // Audio stream olu≈ütur
    const pushStream = sdk.AudioInputStream.createPushStream();
    pushStream.write(audioBuffer);
    pushStream.close();

    const audioConfig = sdk.AudioConfig.fromStreamInput(pushStream);
    const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);

    return new Promise((resolve, reject) => {
      recognizer.recognizeOnceAsync(
        (result: sdk.SpeechRecognitionResult) => {
          if (result.reason === sdk.ResultReason.RecognizedSpeech) {
            console.log(`‚úÖ STT completed: "${result.text}"`);
            resolve(result.text);
          } else {
            console.error(`‚ùå STT failed: ${result.errorDetails}`);
            resolve(null);
          }
          recognizer.close();
        },
        (error: any) => {
          console.error("‚ùå STT error:", error);
          recognizer.close();
          reject(error);
        }
      );
    });

  } catch (error) {
    console.error("‚ùå Azure STT initialization error:", error);
    return null;
  }
}